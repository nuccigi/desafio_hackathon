{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "17zqN1VeGlSds_Ettr25srtolN6-AxcJT",
      "authorship_tag": "ABX9TyM36VHNXbl5ReOqPc16YG9/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nuccigi/desafio_hackathon/blob/main/primeira_entrega.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "hwemmCWZYw0w"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "GobR4yEMYfHC",
        "outputId": "9a9e029a-a013-40b0-ca5f-6e5662423dd3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3638581272.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Cria a pasta se não existir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestino\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Extrai o conteúdo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ],
      "source": [
        "caminho_zip = \"/content/drive/MyDrive/hackathon_2025_templates.zip\"\n",
        "\n",
        "# Pasta de destino\n",
        "destino = \"/content/drive/MyDrive/arquivos_extraidos\"\n",
        "\n",
        "# Cria a pasta se não existir\n",
        "os.makedirs(destino, exist_ok=True)\n",
        "\n",
        "# Extrai o conteúdo\n",
        "with zipfile.ZipFile(caminho_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(destino)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "karv85WRiSAu",
        "outputId": "d14224da-9733-40e0-e07b-d01eedef350e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho de um arquivo Parquet\n",
        "dados1 = \"/content/drive/MyDrive/arquivos_extraidos/hackathon_2025_templates/part-00000-tid-2779033056155408584-f6316110-4c9a-4061-ae48-69b77c7c8c36-4-1-c000.snappy.parquet\"\n",
        "dados2 = \"/content/drive/MyDrive/arquivos_extraidos/hackathon_2025_templates/part-00000-tid-5196563791502273604-c90d3a24-52f2-4955-b4ec-fb143aae74d8-4-1-c000.snappy.parquet\"\n",
        "dados3 = \"/content/drive/MyDrive/arquivos_extraidos/hackathon_2025_templates/part-00000-tid-7173294866425216458-eae53fbf-d19e-4130-ba74-78f96b9675f1-4-1-c000.snappy.parquet\"\n",
        "\n",
        "df1 = pd.read_parquet(dados1)\n",
        "df2 = pd.read_parquet(dados2)\n",
        "df3 = pd.read_parquet(dados3)\n"
      ],
      "metadata": {
        "id": "WqB1SaA7Y-2T"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df1.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQ4UxiwQZ5e2",
        "outputId": "00ae4258-5a77-48ec-9076-68e5bdef212e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   pdv      premise categoria_pdv  zipcode\n",
            "0  2204965430669363375   On Premise  Mexican Rest    30741\n",
            "1  5211957289528622910   On Premise   Hotel/Motel    80011\n",
            "2  9024493554530757353  Off Premise   Convenience    80751\n",
            "3  8659197371382902429   On Premise    Restaurant    80439\n",
            "4  1400854873763881130   On Premise    Restaurant    30093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df2.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vdt8i2qpZ8mN",
        "outputId": "1e93f382-e023-4fba-eee9-1f89c296a89b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     internal_store_id  internal_product_id distributor_id transaction_date  \\\n",
            "0  7384367747233276219   328903483604537190              9       2022-07-13   \n",
            "1  3536908514005606262  5418855670645487653              5       2022-03-21   \n",
            "2  3138231730993449825  1087005562675741887              6       2022-09-06   \n",
            "3  3681167389484217654  1401422983880045188              5       2022-09-11   \n",
            "4  7762413312337359369  6614994347738381720              4       2022-02-18   \n",
            "\n",
            "  reference_date  quantity  gross_value    net_value  gross_profit  \\\n",
            "0     2022-07-01       1.0    38.125000    37.890625     10.042625   \n",
            "1     2022-03-01       6.0   107.250000   106.440002     24.732002   \n",
            "2     2022-09-01       3.0    56.625000    56.220001     14.124002   \n",
            "3     2022-09-01     129.0  1037.160023  1037.160023    156.348026   \n",
            "4     2022-02-01       1.0    26.230000    23.950241      6.550241   \n",
            "\n",
            "     discount     taxes  \n",
            "0    3.950000  0.234375  \n",
            "1   17.100000  0.810000  \n",
            "2    5.250000  0.405000  \n",
            "3  479.880006  0.000000  \n",
            "4    0.000000  2.279758  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df3.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwtWYpoiZ9Be",
        "outputId": "24145c09-9cb7-4b61-b3ee-652a0973f56a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               produto          categoria  \\\n",
            "0  2282334733936076502  Distilled Spirits   \n",
            "1  6091840953834683482  Distilled Spirits   \n",
            "2  1968645851245092408  Distilled Spirits   \n",
            "3   994706710729219179              Draft   \n",
            "4  9209550539540384349        Non-Alcohol   \n",
            "\n",
            "                              descricao              tipos          label  \\\n",
            "0           JOSEPH CARTRON CAFÉ LIQUEUR  Distilled Spirits           Core   \n",
            "1  SPRINGBANK 18 YEAR SINGLE MALT 700ML  Distilled Spirits      Specialty   \n",
            "2     J BRANDT TRIPLE SEC 12/750ML 30PF  Distilled Spirits  Private Label   \n",
            "3      REFORMATION CASHMERE IPA 1/4 KEG              Draft         In&Out   \n",
            "4               HELLA MOSCOW MULE 750ML        Non Alcohol           Core   \n",
            "\n",
            "          subcategoria                               marca  \\\n",
            "0  Liqueurs & Cordials                 Joseph Cartron Cafe   \n",
            "1        Scotch Whisky      Springbank 18 Year Single Malt   \n",
            "2  Liqueurs & Cordials                 J Brandt Triple Sec   \n",
            "3          Other Draft  Reformation Cashmere Fresh Hop IPA   \n",
            "4               Mixers           Hella Bitters Bloody Mary   \n",
            "\n",
            "                    fabricante  \n",
            "0                     Spiribam  \n",
            "1  Pacific Edge Wine & Spirits  \n",
            "2              Sazerac Spirits  \n",
            "3          Reformation Brewery  \n",
            "4             Hella Bitter Llc  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "unificando as três tabelas e agregando por semana"
      ],
      "metadata": {
        "id": "dg4_VQPnafsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1['pdv'] = df1['pdv'].astype(str)\n",
        "df2['internal_store_id'] = df2['internal_store_id'].astype(str)\n",
        "df3['produto'] = df3['produto'].astype(str)\n",
        "df2['internal_product_id'] = df2['internal_product_id'].astype(str)"
      ],
      "metadata": {
        "id": "n-DTjTASaUg0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged = df2.merge(df1, left_on=\"internal_store_id\", right_on=\"pdv\", how=\"left\")\n",
        "df_merged = df_merged.merge(df3, left_on=\"internal_product_id\", right_on=\"produto\", how=\"left\")"
      ],
      "metadata": {
        "id": "93cmuMEwaXGy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged['reference_date'] = pd.to_datetime(df_merged['reference_date'])\n",
        "df_merged['ano'] = df_merged['reference_date'].dt.year\n",
        "df_merged['semana'] = df_merged['reference_date'].dt.isocalendar().week\n",
        "\n",
        "df_semana = (\n",
        "    df_merged.groupby(['ano','semana','pdv','internal_product_id',\n",
        "                       'categoria','marca','fabricante','premise','categoria_pdv'])\n",
        "             .agg({'quantity':'sum'})\n",
        "             .reset_index()\n",
        ")"
      ],
      "metadata": {
        "id": "0ajISYG5aZ-R"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_semana['mes'] = pd.to_datetime(df_semana['ano'].astype(str) + df_semana['semana'].astype(str) + '1', format='%G%V%u').dt.month"
      ],
      "metadata": {
        "id": "uGM-fT6FasD2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_semana = df_semana.sort_values(['pdv','internal_product_id','ano','semana'])\n",
        "\n",
        "df_semana['lag1'] = df_semana.groupby(['pdv','internal_product_id'])['quantity'].shift(1)\n",
        "df_semana['lag2'] = df_semana.groupby(['pdv','internal_product_id'])['quantity'].shift(2)\n",
        "df_semana['lag4'] = df_semana.groupby(['pdv','internal_product_id'])['quantity'].shift(4)\n",
        "df_semana['rolling_mean_4'] = df_semana.groupby(['pdv','internal_product_id'])['quantity'].shift(1).rolling(window=4).mean()"
      ],
      "metadata": {
        "id": "aFRHAl_-auYd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = df_semana[df_semana['ano'] == 2022]\n",
        "# Teste = previsões para ano=2023, semanas 1 a 5"
      ],
      "metadata": {
        "id": "y1iJzkYda0b0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usar semanas 49 a 52 de 2022 para calcular a média\n",
        "baseline_forecast = (\n",
        "    train[train['semana'] > 48]  # últimas 4 semanas\n",
        "    .groupby(['pdv','internal_product_id'])['quantity']\n",
        "    .mean()\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# Renomear colunas\n",
        "baseline_forecast = baseline_forecast.rename(\n",
        "    columns={'internal_product_id':'produto', 'quantity':'quantidade'}\n",
        ")"
      ],
      "metadata": {
        "id": "2ofhZc-giLHs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar dataframe com semanas 1 a 5\n",
        "horizonte = pd.DataFrame({'semana': range(1, 6)})\n",
        "\n",
        "# Expandir previsões para todas as 5 semanas\n",
        "baseline_forecast = baseline_forecast.merge(horizonte, how='cross')\n",
        "\n",
        "# Reordenar colunas\n",
        "baseline_forecast = baseline_forecast[['semana','pdv','produto','quantidade']]"
      ],
      "metadata": {
        "id": "IMI5ZDBaiLB0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# ===============================\n",
        "# 1. Dados de treino (2022)\n",
        "# ===============================\n",
        "train = df_semana[df_semana['ano'] == 2022]\n",
        "\n",
        "# ===============================\n",
        "# 2. Calcular baseline da média das 4 últimas semanas\n",
        "# ===============================\n",
        "baseline_valid = train.dropna(subset=['rolling_mean_4'])\n",
        "\n",
        "# Previsão = rolling_mean_4\n",
        "baseline_valid['forecast'] = baseline_valid['rolling_mean_4']\n",
        "\n",
        "# ===============================\n",
        "# 3. Usar apenas semanas 49–52 como validação\n",
        "# ===============================\n",
        "valid_real = baseline_valid[baseline_valid['semana'] > 48]\n",
        "\n",
        "y_true = valid_real['quantity']\n",
        "y_pred = valid_real['forecast']\n",
        "\n",
        "# ===============================\n",
        "# 4. Calcular métricas\n",
        "# ===============================\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "wmape = (abs(y_true - y_pred).sum()) / y_true.sum()\n",
        "accuracy = 1 - wmape\n",
        "\n",
        "print(f\"MAE   : {mae:.2f}\")\n",
        "print(f\"WMAPE : {wmape:.2%}\")\n",
        "print(f\"Accuracy: {accuracy:.2%}\")"
      ],
      "metadata": {
        "id": "QOH14KTAiK4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5d55646-17be-4075-fca7-5d4ad535cc93"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Validação do Baseline (Média 4 semanas)\n",
            "MAE   : 3.14\n",
            "WMAPE : 49.45%\n",
            "Accuracy: 50.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1572935070.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  baseline_valid['forecast'] = baseline_valid['rolling_mean_4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Garantir que a previsão seja inteiro\n",
        "baseline_forecast['quantidade'] = baseline_forecast['quantidade'].round().astype(int)\n",
        "\n",
        "# Exportar para CSV no formato solicitado\n",
        "baseline_forecast.to_csv(\"previsao.csv\", sep=\";\", index=False, encoding=\"utf-8\")"
      ],
      "metadata": {
        "id": "8BxqfJ9njnPY"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}